{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd #用於匯入、操作表格資料之函式庫\n#用於資料可視化之函式庫\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport sklearn #機器學習演算法函式庫\n\ntrain = pd.read_csv('../input/mobile-price-classification/train.csv')\ntest = pd.read_csv('../input/mobile-price-classification/test.csv')\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-04T13:01:23.504380Z","iopub.execute_input":"2022-03-04T13:01:23.504652Z","iopub.status.idle":"2022-03-04T13:01:23.679491Z","shell.execute_reply.started":"2022-03-04T13:01:23.504624Z","shell.execute_reply":"2022-03-04T13:01:23.678355Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">查看資料欄位大致狀況</font>","metadata":{}},{"cell_type":"code","source":"train.head() #使用head()查看前5筆資料，預設值為5","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:27.698322Z","iopub.execute_input":"2022-03-04T13:01:27.698633Z","iopub.status.idle":"2022-03-04T13:01:27.735037Z","shell.execute_reply.started":"2022-03-04T13:01:27.698599Z","shell.execute_reply":"2022-03-04T13:01:27.734123Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test.drop('id',axis=1,inplace=True) #刪除id欄位，因為是多餘的\ntest.head()  #使用head()查看前5筆資料，預設值為5","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:29.570024Z","iopub.execute_input":"2022-03-04T13:01:29.570731Z","iopub.status.idle":"2022-03-04T13:01:29.592650Z","shell.execute_reply.started":"2022-03-04T13:01:29.570685Z","shell.execute_reply":"2022-03-04T13:01:29.592062Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"<font size=5>查看目標欄位(特徵)在訓練集中的資料分布</font>\n<p>從此專案得知我們需要根據其他特徵來預測手機價格範圍，先從訓練集中的price_range欄位查看資料數量的分布狀況</p>","metadata":{}},{"cell_type":"code","source":"sns.countplot(train['price_range']) #查看目標特徵中資料在價錢範圍的分布","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:31.065939Z","iopub.execute_input":"2022-03-04T13:01:31.066605Z","iopub.status.idle":"2022-03-04T13:01:31.256120Z","shell.execute_reply.started":"2022-03-04T13:01:31.066571Z","shell.execute_reply":"2022-03-04T13:01:31.254862Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train.shape,test.shape #訓練集資料總筆數為2000筆、測試集資料總筆數為1000筆，欄位數皆為21行","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:32.686338Z","iopub.execute_input":"2022-03-04T13:01:32.686606Z","iopub.status.idle":"2022-03-04T13:01:32.692823Z","shell.execute_reply.started":"2022-03-04T13:01:32.686579Z","shell.execute_reply":"2022-03-04T13:01:32.691790Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<font size=5>在進行模型訓練前，檢查資料是否含有空值，並且查看各欄位詳細狀況，接著了解各欄位之間的relation</font>","metadata":{}},{"cell_type":"code","source":"\"\"\"\n透過insnull()檢測訓練集中的資料是否有空值回傳一個\n含有真偽值資料的dataframe，如有空值回傳true，否則回傳false;\n使用sum()來讓各欄位為基準加總真偽值，更清楚的顯示\n各欄位的所有筆資料是否有不同真偽值存在\n\"\"\"\ntrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:35.009093Z","iopub.execute_input":"2022-03-04T13:01:35.009647Z","iopub.status.idle":"2022-03-04T13:01:35.018447Z","shell.execute_reply.started":"2022-03-04T13:01:35.009610Z","shell.execute_reply":"2022-03-04T13:01:35.017529Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train.info() #查看訓練集中各欄位資料的類型","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:37.118682Z","iopub.execute_input":"2022-03-04T13:01:37.119377Z","iopub.status.idle":"2022-03-04T13:01:37.139170Z","shell.execute_reply.started":"2022-03-04T13:01:37.119329Z","shell.execute_reply":"2022-03-04T13:01:37.138306Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"test.info() #查看測試集中各欄位資料的類型","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:38.665490Z","iopub.execute_input":"2022-03-04T13:01:38.666103Z","iopub.status.idle":"2022-03-04T13:01:38.679919Z","shell.execute_reply.started":"2022-03-04T13:01:38.666065Z","shell.execute_reply":"2022-03-04T13:01:38.679069Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train.describe() #描述2000筆資料在各欄位的資料筆數、平均值、標準差、最小值、25百分位的值、中位數、75百分位的值、最大值","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:40.355639Z","iopub.execute_input":"2022-03-04T13:01:40.356288Z","iopub.status.idle":"2022-03-04T13:01:40.426202Z","shell.execute_reply.started":"2022-03-04T13:01:40.356244Z","shell.execute_reply":"2022-03-04T13:01:40.425381Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,20)) #設定熱力圖顯示的大小\nsns.heatmap(train.corr(),annot=True,cmap=plt.cm.Blues) #透過seaborn檢查欄位關聯性，發現ram對於價格範圍的影響很大\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:42.498250Z","iopub.execute_input":"2022-03-04T13:01:42.498544Z","iopub.status.idle":"2022-03-04T13:01:44.728767Z","shell.execute_reply.started":"2022-03-04T13:01:42.498512Z","shell.execute_reply":"2022-03-04T13:01:44.728080Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"<font size=5>訓練模型前先對訓練資料進行分割成要訓練的資料及測試的資料</font>","metadata":{}},{"cell_type":"code","source":"X = train.drop('price_range',axis=1) #將price_range欄位剃除，只留下剩下的欄位用於對目標欄位:price_range進行訓練\ny = train['price_range'] #設定目標欄位","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:47.936685Z","iopub.execute_input":"2022-03-04T13:01:47.936979Z","iopub.status.idle":"2022-03-04T13:01:47.942545Z","shell.execute_reply.started":"2022-03-04T13:01:47.936944Z","shell.execute_reply":"2022-03-04T13:01:47.941614Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.1,random_state=0) #隨機切分驗證資料來防止模型過擬合","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:49.801770Z","iopub.execute_input":"2022-03-04T13:01:49.802083Z","iopub.status.idle":"2022-03-04T13:01:49.823893Z","shell.execute_reply.started":"2022-03-04T13:01:49.802050Z","shell.execute_reply":"2022-03-04T13:01:49.823257Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">透過StandardScaler對訓練集和測試集進行標準化</font>\n<p>因為透過對資料的標準化，讓原本單位不一樣的資料能映射到另一個空間而不改變其原本的資料分布，可以提升模型收斂的速度使訓練時間縮短</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler() #建立StandardScaler物件以對資料標準化\nX_train = sc.fit_transform(X_train) #先使用fit_transform()對訓練集做fit和transform的動作，fit用於找到一些指標，比如標準差、平均值、最大最小值等來進行後續的transform\nX_test = sc.transform(X_test) #使用transform()來依據前面的訓練集所找到的標準差、平均值等等指標來來進行transform，用來保證訓練集和測試集是在同一個標準來進行訓練和測試","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:52.168398Z","iopub.execute_input":"2022-03-04T13:01:52.168790Z","iopub.status.idle":"2022-03-04T13:01:52.180532Z","shell.execute_reply.started":"2022-03-04T13:01:52.168762Z","shell.execute_reply":"2022-03-04T13:01:52.179744Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">使用classification_report函式庫計算出Recall、Precision、F1-score、Support以評估模型</font>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:01:53.963949Z","iopub.execute_input":"2022-03-04T13:01:53.964241Z","iopub.status.idle":"2022-03-04T13:01:53.968400Z","shell.execute_reply.started":"2022-03-04T13:01:53.964213Z","shell.execute_reply":"2022-03-04T13:01:53.967415Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">建立SVM模型</font>\n<p>通過不同分類器來比較模型準確度</p>","metadata":{}},{"cell_type":"code","source":"from sklearn import svm\n\nlinearSvcModel=svm.LinearSVC(C=1, max_iter=10000) #建立線性SVC分類器\nlinearSvcModel.fit(X_train, Y_train) #使用訓練集訓練模型\npredicted_train_linear=linearSvcModel.predict(X_train) #使用訓練集預測\npredicted_test_linear=linearSvcModel.predict(X_test) #使用測試集預測\nprint('linearSvcModel')\nprint('train:',predicted_train_linear,'\\ntest:',predicted_test_linear)\naccuracy1 = linearSvcModel.score(X_train, Y_train) #計算訓練集準確率\nprint('accuracy_train',accuracy1)\naccuracy1 = linearSvcModel.score(X_test, Y_test) #計算測試集準確率\nprint('accuracy_test',accuracy1)\nprint('report:\\n',classification_report(Y_test,predicted_test_linear))\nplt.figure(figsize=(5,5))\nsns.heatmap(confusion_matrix(Y_test, predicted_test_linear),annot=True,cmap=plt.cm.Blues)\nplt.show()\n\n\nsvcModel=svm.SVC(kernel='linear', C=1) #建立核為線性的SVC分類器\nsvcModel.fit(X_train, Y_train) #使用訓練集訓練模型\npredicted_train_linear_ker=svcModel.predict(X_train) #使用訓練集預測\npredicted_test_linear_ker=svcModel.predict(X_test) #使用測試集預測\nprint('\\nSvcModelWithLinear')\nprint('train:',predicted_train_linear_ker,'\\ntest:',predicted_test_linear_ker)\naccuracy2 = svcModel.score(X_train, Y_train) #計算訓練集準確率\nprint('accuracy_train',accuracy2)\naccuracy2 = svcModel.score(X_test, Y_test) #計算測試集準確率\nprint('accuracy_test',accuracy2)\nprint('report:\\n',classification_report(Y_test,predicted_test_linear_ker))\nplt.figure(figsize=(5,5))\nsns.heatmap(confusion_matrix(Y_test, predicted_test_linear_ker),annot=True,cmap=plt.cm.Blues)\nplt.show()\n\npolyModel=svm.SVC(kernel='poly', degree=3, gamma='auto', C=1) #建立核為多項式轉換的SVC分類器\npolyModel.fit(X_train, Y_train) #使用訓練集訓練模型\npredicted_train_poly=polyModel.predict(X_train) #使用訓練集預測\npredicted_test_poly=polyModel.predict(X_test) #使用測試集預測\nprint('\\nPolyModel')\nprint('train:',predicted_train_poly,'\\ntest:',predicted_test_poly)\naccuracy3 = polyModel.score(X_train, Y_train) #計算訓練集準確率\nprint('accuracy_train',accuracy3)\naccuracy3 = polyModel.score(X_test, Y_test) #計算測試集準確率\nprint('accuracy_test',accuracy3)\nprint('report:\\n',classification_report(Y_test,predicted_test_poly))\nplt.figure(figsize=(5,5))\nsns.heatmap(confusion_matrix(Y_test, predicted_test_poly),annot=True,cmap=plt.cm.Blues)\nplt.show()\n\nrbfModel=svm.SVC(kernel='rbf', gamma=0.2, C=1) #建立核為高斯轉換的SVC分類器\nrbfModel.fit(X_train, Y_train) #使用訓練集訓練模型\npredicted_train_rbf=rbfModel.predict(X_train) #使用訓練集預測\npredicted_test_rbf=rbfModel.predict(X_test) #使用測試集預測\nprint('\\nRBFModel')\nprint('train:',predicted_train_rbf,'\\ntest:',predicted_test_rbf)\naccuracy4 = rbfModel.score(X_train, Y_train) #計算訓練集準確率\nprint('accuracy_train',accuracy4)\naccuracy4 = rbfModel.score(X_test, Y_test) #計算測試集準確率\nprint('accuracy_test',accuracy4)\nprint('report:\\n',classification_report(Y_test,predicted_test_rbf))\nplt.figure(figsize=(5,5))\nsns.heatmap(confusion_matrix(Y_test, predicted_test_rbf),annot=True,cmap=plt.cm.Blues)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:12:57.857425Z","iopub.execute_input":"2022-03-04T13:12:57.857721Z","iopub.status.idle":"2022-03-04T13:13:00.113802Z","shell.execute_reply.started":"2022-03-04T13:12:57.857688Z","shell.execute_reply":"2022-03-04T13:13:00.112780Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">建立KNN模型</font>","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknnModel = KNeighborsClassifier(n_neighbors=3) #建立K-近鄰模型\nknnModel.fit(X_train, Y_train) #使用訓練集訓練模型\npredicted_train = knnModel.predict(X_train) #使用訓練集預測\npredicted_test = knnModel.predict(X_test) #使用測試集預測\nprint('train:',predicted_train,'\\ntest:',predicted_test)\naccuracy = knnModel.score(X_train, Y_train) #計算訓練集準確率\nprint('accuracy_train',accuracy)\naccuracy = knnModel.score(X_test, Y_test) #計算測試集準確率\nprint('accuracy_test',accuracy)\nprint('report:\\n',classification_report(Y_test,predicted_test))\nplt.figure(figsize=(5,5))\nsns.heatmap(confusion_matrix(Y_test, predicted_test),annot=True,cmap=plt.cm.Blues)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:31:35.775948Z","iopub.execute_input":"2022-03-04T13:31:35.776308Z","iopub.status.idle":"2022-03-04T13:31:36.531497Z","shell.execute_reply.started":"2022-03-04T13:31:35.776272Z","shell.execute_reply":"2022-03-04T13:31:36.530017Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">建立Decision Tree</font>","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom keras.utils import np_utils #對目標特徵做one-hot-encoding，讓類別轉成0跟1以方便程式計算\n#print(Y_train.shape)\n#print(Y_test.shape)\n#X_test = np_utils.to_categorical(X_test)\ndecisionTreeModel = DecisionTreeRegressor(max_depth=4, splitter='best') #建立DecisionTreeRegressor模型\ndecisionTreeModel.fit(X_train, Y_train) #使用訓練集訓練模型\npredicted_train = decisionTreeModel.predict(X_train) #使用訓練集預測\npredicted_test = decisionTreeModel.predict(X_test) #使用測試集預測\nprint('train:',predicted_train,'\\ntest:',predicted_test)\naccuracy = decisionTreeModel.score(X_train, Y_train) #計算訓練集準確率\nprint('accuracy_train',accuracy)\naccuracy = decisionTreeModel.score(X_test, Y_test) #計算測試集準確率\nprint('accuracy_test',accuracy) \nprint('report:\\n',classification_report(Y_test,predicted_test))\nplt.figure(figsize=(5,5))\nsns.heatmap(confusion_matrix(Y_test, predicted_test),annot=True,cmap=plt.cm.Blues)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:33:13.662499Z","iopub.execute_input":"2022-03-04T13:33:13.662953Z","iopub.status.idle":"2022-03-04T13:33:13.712647Z","shell.execute_reply.started":"2022-03-04T13:33:13.662903Z","shell.execute_reply":"2022-03-04T13:33:13.711361Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">建立Random Forest</font>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrandomForestModel = RandomForestClassifier(n_estimators=100, criterion = 'gini') #建立Random Forest Classifier模型\nrandomForestModel.fit(X_train, Y_train) #使用訓練集訓練模型\npredicted_train = randomForestModel.predict(X_train) #使用訓練集預測\npredicted_test = decisionTreeModel.predict(X_test) #使用測試集預測\nprint('train:',predicted_train,'\\ntest:',predicted_test)\naccuracy = randomForestModel.score(X_train, Y_train) #計算訓練集準確率\nprint('accuracy_train',accuracy)\naccuracy = randomForestModel.score(X_test, Y_test) #計算測試集準確率\nprint('accuracy_test',accuracy)\nprint('report:\\n',classification_report(Y_test,predicted_test))\nplt.figure(figsize=(5,5))\nsns.heatmap(confusion_matrix(Y_test, predicted_test),annot=True,cmap=plt.cm.Blues)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T13:33:18.892785Z","iopub.execute_input":"2022-03-04T13:33:18.893347Z","iopub.status.idle":"2022-03-04T13:33:19.473463Z","shell.execute_reply.started":"2022-03-04T13:33:18.893299Z","shell.execute_reply":"2022-03-04T13:33:19.472220Z"},"trusted":true},"execution_count":42,"outputs":[]}]}