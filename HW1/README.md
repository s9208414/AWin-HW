## 索引
* [目的](#目的) 
* [匯入相關函式庫](#匯入相關函式庫)
* [讀取並整理資料](#讀取並整理資料)
* [資料前處理](#資料前處理)
* [訓練模型](#訓練模型)
* [模型評估](#模型評估)

## 目的
#### 本專案期望使用機器學習中的各種分類器透過輸入欲預測之手機各方面特徵，以對未知的手機之價格做預測。本專案會先讀取資料並視覺化以了解資料的架構，因為手機各方面之特徵都有可能對手機價格範圍產生影響，因此要了解各特徵對於手機價格是否有相關，假如手機可充飽的電量與手機價格產生正相關，代表電量愈高，手機價格範圍也會隨之愈高。對資料進行特徵關聯性的探討有助於了解特徵彼此的影響。常見的機器學習分類演算法有:
* [線性分類器](#線性分類器) 
* [線性核的分類器](#線性核的分類器)
* [多項式轉換的非線性分類器](#多項式轉換的非線性分類器)
* [高斯核的非線性分類器](#高斯核的非線性分類器)
* [近鄰演算法](#近鄰演算法)
* [決策樹](#決策樹)
* [隨機森林](#隨機森林)
#### 而本專案會使用這7個分類器去訓練出對應的模型，並透過混淆矩陣及相關評估指標來評估模型。接著就是本專案執行的步驟
## 匯入相關函式庫 
###### 1. pandas:用來匯入相關表格資料
###### 2. matplotlib.pyplot、seaborn:用來視覺化輸入資料以方便進行資料整理
###### 3. sklearn:內涵機器學習模型相關函式
## 讀取並整理資料
###### 1. 以head()、describe()函式來查看大致狀況
###### 2. 查看資料是否含有空值，以及透過seaborn的heatmap()查看各欄位間的關聯性，以及目標特徵(price_range)與其他特徵的關聯性，是很重要的步驟
## 資料前處理
###### 1. 將訓練資料透過train_test_split()拆分成要訓練的資料以及測試的資料
###### 2. 將資料標準化以加快模型收斂速度
## 訓練模型
#### SVM
###### SVM用於在二分類問題的分類，本專案希望透過給定欲預測的樣本特徵來預測價格範圍(多類別分類)，此模型會有一個超平面用於將資料分類，由於有4個(0、1、2、3)價格範圍(類別)用於目標預測，因此會有C(4,2)個超平面用於分類(因為每2個類別生成1個超平面)。SVM對於多分類策略有2種:
###### 1.one-vs-one(ovo)
###### 2.one-vs-rest(ovr)
###### 本專案採取擬和速度快但可能分類較沒ovo那麼準確的ovr，使用SVM下的4個分類器進行模型擬合。
#### KNN
###### 透過給定一個k值來決定欲預測之樣本將會被分類到哪一個價格範圍。假如現有一欲預測之樣本，計算該樣本與其他樣本的歐式距離(會採用歐式距離是因為價格範圍為連續型資料)，並找出小於或等於k值得所有鄰近資料，透過這些鄰近的資料所屬類別，將該樣本分類為最多資料所屬的類別。
#### decision tree
###### 決策樹的生成式建立於每一層節點要用甚麼特徵作為分類基準，以本專案來說，現有2個特徵用於建立決策樹: ram、battery_power，這兩者作為樹建立的順序可能會有影響，比如或許第一層節點為battery_power而第二層為ram建立的決策樹效果可能沒有兩者順序對調來得好。所以決策樹的建立是希望能將欲預測之目標在每一層的分類中能準確的分類，如此模型的分類能力才有可能比較好。
#### random forest
###### 隨機森林是由好幾個決策樹組成，每一個決策樹可以共同負擔原先只有一個樹的分類責任，所以能把樹的深度設淺一點來讓模型相較於決策樹不容易過擬合，又可以達到好的分類效果。隨機森林的建立是透過隨機分類訓練資料以及訓練的特徵給每一個樹來將資料擬合至模型。目標的預測是採多個樹的多數決投票制進行分類。
## 模型評估
#### 以此次專案來說，recall會比precision還重要一些，因為預測手機價格範圍應是求正確，而recall這個評估標準是如果在該預測為正樣本中卻預測其為負樣本，也就是說如果本該預測其為範圍1，卻預測其為4，因此應該要較重視recall的值，希望該值能愈大愈好，代表其預測錯誤的機率愈低。假設本專案皆用預測手機價格範圍為0來評估模型

##### 線性分類器
###### precison為42/42+3+0+0= 42/45
###### recall為42/42+0+0+0= 1
###### F1-score為2/(45/42+(1))= 84/87
###### accuracy為42+28+34+60/42+28+34+60+3+0+0+0+0+0= 164/167
![image](https://user-images.githubusercontent.com/68068287/156771982-58aecbe7-a878-43cf-b31a-5deacd9d25dc.png)

##### 線性核的分類器
###### precison為41/41+1+0+0= 41/42
###### recall為41/41+1+0+0= 41/42
###### F1-score為2/(42/41+42/41)= 82/84
###### accuracy為41+48+44+60/41+48+44+60+1+0+0+1+0+0= 193/195
![image](https://user-images.githubusercontent.com/68068287/156772076-3c55df27-7c38-44b2-9297-4909ce8de7e8.png)

##### 多項式轉換的非線性分類器
###### precison為37/37+6+0+0= 37/43
###### recall為37/37+5+0+0= 37/42
###### F1-score為2/(43/37+42/37)= 74/85
###### accuracy為37+31+36+48/37+31+36+48+6+0+0+5+0+0= 152/163
![image](https://user-images.githubusercontent.com/68068287/156772115-d80e1b9a-b614-4110-acb4-59ddb5a66c13.png)

##### 高斯核的非線性分類器
###### precison為34/34+7+0+0= 34/41
###### recall為34/34+8+0+0= 34/42
###### F1-score為2/(41/34+42/34)= 68/83
###### accuracy為34+27+34+46/34+27+34+46+7+0+0+8+0+0= 141/156
![image](https://user-images.githubusercontent.com/68068287/156772151-7fab2ade-740c-418c-890f-a9ee6466979f.png)

##### 近鄰演算法
###### precison為29/29+29+5+2= 29/65
###### recall為29/29+12+0+1= 29/42
###### F1-score為2/(65/29+42/29)= 58/107
###### accuracy為29+16+15+29/29+16+15+29+29+5+2+12+0+1= 89/109
![image](https://user-images.githubusercontent.com/68068287/156772271-b0e3d49d-dce9-4a65-bffe-32a9bc21e280.png)

###### 決策樹
###### precison為39/39+3+0+0= 13/14
###### recall為39/39+3+0+0= 13/14
###### F1-score為2/(14/13+14/13)= 13/14
###### accuracy為39+39+39+55/39+39+39+55+3+0+0+3+0+0= 86/89
![image](https://user-images.githubusercontent.com/68068287/157248278-b59a353d-b951-498d-9040-2e187251d34b.png)
###### 隨機森林
###### precison為39/39+3+0+0= 13/14
###### recall為39/39+3+0+0= 13/14
###### F1-score為2/(14/13+14/13)= 13/14
###### accuracy為39+39+39+55/39+39+39+55+3+0+0+3+0+0= 86/89
![image](https://user-images.githubusercontent.com/68068287/157248329-5ee6a0c5-b58e-4332-b710-ac1e1da2967d.png)

