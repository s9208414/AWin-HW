## 索引
* [目的](#目的) 
* [匯入相關函式庫](#匯入相關函式庫)
* [讀取並整理資料](#讀取並整理資料)
* [資料前處理](#資料前處理)
* [訓練模型](#訓練模型)
* [模型評估](#模型評估)

## 目的
#### 本專案期望使用機器學習中的各種分類器透過輸入欲預測之手機各方面特徵，以對未知的手機之價格做預測。本專案會先讀取資料並視覺化以了解資料的架構，因為手機各方面之特徵都有可能對手機價格範圍產生影響，因此要了解各特徵對於手機價格是否有相關，假如手機可充飽的電量與手機價格產生正相關，代表電量愈高，手機價格範圍也會隨之愈高。對資料進行特徵關聯性的探討有助於了解特徵彼此的影響。常見的機器學習分類演算法有:
* [線性分類器](#線性分類器) 
* [線性核的分類器](#線性核的分類器)
* [多項式轉換的非線性分類器](#多項式轉換的非線性分類器)
* [高斯核的非線性分類器](#高斯核的非線性分類器)
* [近鄰演算法](#近鄰演算法)
* [決策樹](#決策樹)
* [隨機森林](#隨機森林)
#### 而本專案會使用這7個分類器去訓練出對應的模型，並透過混淆矩陣及相關評估指標來評估模型。接著就是本專案執行的步驟
## 匯入相關函式庫 
###### 1. pandas:用來匯入相關表格資料
###### 2. matplotlib.pyplot、seaborn:用來視覺化輸入資料以方便進行資料整理
###### 3. sklearn:內涵機器學習模型相關函式
## 讀取並整理資料
###### 1. 以head()、describe()函式來查看大致狀況
###### 2. 查看資料是否含有空值，以及透過seaborn的heatmap()查看各欄位間的關聯性，以及目標特徵(price_range)與其他特徵的關聯性，是很重要的步驟
## 資料前處理
###### 1. 將訓練資料透過train_test_split()拆分成要訓練的資料以及測試的資料
###### 2. 將資料標準化以加快模型收斂速度
## 訓練模型

## 模型評估
#### 以此次專案來說，recall會比precision還重要一些，因為預測手機價格範圍應是求正確，而recall這個評估標準是如果在該預測為正樣本中卻預測其為負樣本，也就是說如果本該預測其為範圍1，卻預測其為4，因此應該要較重視recall的值，希望該值能愈大愈好，代表其預測錯誤的機率愈低。假設本專案皆用預測手機價格範圍為0來評估模型

##### 線性分類器
###### precison為42/42+3+0+0= 42/45
###### recall為42/42+0+0+0= 1
###### F1-score為2/(45/42+(1))= 84/87
###### accuracy為42+28+34+60/42+28+34+60+3+0+0+0+0+0= 164/167
![image](https://user-images.githubusercontent.com/68068287/156771982-58aecbe7-a878-43cf-b31a-5deacd9d25dc.png)

##### 線性核的分類器
###### precison為41/41+1+0+0= 41/42
###### recall為41/41+1+0+0= 41/42
###### F1-score為2/(42/41+42/41)= 82/84
###### accuracy為41+48+44+60/41+48+44+60+1+0+0+1+0+0= 193/195
![image](https://user-images.githubusercontent.com/68068287/156772076-3c55df27-7c38-44b2-9297-4909ce8de7e8.png)

##### 多項式轉換的非線性分類器
###### precison為37/37+6+0+0= 37/43
###### recall為37/37+5+0+0= 37/42
###### F1-score為2/(43/37+42/37)= 74/85
###### accuracy為37+31+36+48/37+31+36+48+6+0+0+5+0+0= 152/163
![image](https://user-images.githubusercontent.com/68068287/156772115-d80e1b9a-b614-4110-acb4-59ddb5a66c13.png)

##### 高斯核的非線性分類器
###### precison為34/34+7+0+0= 34/41
###### recall為34/34+8+0+0= 34/42
###### F1-score為2/(41/34+42/34)= 68/83
###### accuracy為34+27+34+46/34+27+34+46+7+0+0+8+0+0= 141/156
![image](https://user-images.githubusercontent.com/68068287/156772151-7fab2ade-740c-418c-890f-a9ee6466979f.png)

##### 近鄰演算法
###### precison為29/29+29+5+2= 29/65
###### recall為29/29+12+0+1= 29/42
###### F1-score為2/(65/29+42/29)= 58/107
###### accuracy為29+16+15+29/29+16+15+29+29+5+2+12+0+1= 89/109
![image](https://user-images.githubusercontent.com/68068287/156772271-b0e3d49d-dce9-4a65-bffe-32a9bc21e280.png)

###### 決策樹
###### precison為39/39+3+0+0= 13/14
###### recall為39/39+3+0+0= 13/14
###### F1-score為2/(14/13+14/13)= 13/14
###### accuracy為39+39+39+55/39+39+39+55+3+0+0+3+0+0= 86/89
![image](https://user-images.githubusercontent.com/68068287/157248278-b59a353d-b951-498d-9040-2e187251d34b.png)
###### 隨機森林
###### precison為39/39+3+0+0= 13/14
###### recall為39/39+3+0+0= 13/14
###### F1-score為2/(14/13+14/13)= 13/14
###### accuracy為39+39+39+55/39+39+39+55+3+0+0+3+0+0= 86/89
![image](https://user-images.githubusercontent.com/68068287/157248329-5ee6a0c5-b58e-4332-b710-ac1e1da2967d.png)

