## 索引
* [目的](#目的) 
* [匯入相關函式庫](#匯入相關函式庫)
* [讀取資料](#讀取資料)
* [輸入統一](#輸入統一)
* [資料標準化](#資料標準化)
* [one-hot-encoding](#one-hot-encoding)
* [模型建立](#模型建立)
* [模型訓練](#模型訓練)
* [模型儲存](#模型儲存)
* [訓練過程](#訓練過程)
* [模型載入](#模型載入)
* [模型評估](#模型評估)
* [結語](#結語)
## 目的
#### 本專案希望藉由深度學習中的卷積神經網路(convolutional neural network)對圖像進行花品種的分類。本專案使用CNN而不是使用DNN的目的在於CNN的權重參數比DNN少，使得擬合CNN模型的速度較快且較不易   
過擬合，並且能使用較少的訓練集就能訓練出與DNN相同的模型能力，且通常圖像辨識中的目標經常以不同角度、位置、大小等等呈現，CNN的優勢在於它依然可以較正確的識別目標，因此本專案採用CNN作為網路架構來   訓練圖像辨識之模型。
#### 以下是本專案執行的步驟
## 匯入相關函式庫 
###### 1. numpy: 用來轉換一般串列成ndarray，因其提供很多串列運算，方便後續操作
###### 2. os: 資料路徑操作
###### 3. cv2: 讀入圖片檔案所需
###### 4. random: 用來打散原資料，方便後續分割隨機資料成訓練集、驗證集、測試集
###### 5. sklearn.model_selection: 分割資料所需
###### 6. keras.utils: 用來對目標特徵資料做one-hot-encoding，讓類別轉成0跟1以方便程式計算
###### 7. keras.models: 用以產生模型的初始序列物件、模型儲存及載入
###### 8. keras.layers: 建立模型的各類網路層所需
###### 9. matplotlib.pyplot: 繪製訓練過程的狀況
###### 10. sklearn.metrics: 提供confusion matrix以評估模型

## 讀取資料
#### 透過opencv讀取圖片資料，搭配路徑名稱(花的種類)以及種類所對應的數字來分類圖片，並以list的形式再存到整個資料集所形成的list。
## 打散資料
#### 透過random的shuffle()傳入整個資料集，隨機打散資料，並依目標特徵及其他特徵來分類資料成Y及X。
## 輸入統一
#### 因為圖片尺寸可能大小不一，而一個模型的訓練需要規格統一的輸入才能訓練，因此將所有圖片大小先重塑成固定大小(設150*150)。
## 資料標準化
#### 因為每一張圖片的所有像素值都是0 ~ 255，對每一像素除以255讓所有像素的值落在0~1之間，電腦會較容易處理範圍較小的資料，使梯度下降的時間可以得到縮短，所以可以加快收斂的速度。
## one-hot-encoding
#### 將目標特徵轉成有序的關係，將5個分類值(0~4)轉成5個二進位數字。one-hot-encoding會賦予每一個分類一個暫存器位，透過此方式能幫助分類器處理資料問題。
## 模型建立
#### 此任務使用CNN。CNN是藉由眷積層以及池化層的組合和全連階層的組合而來，其中卷積層使用Conv2D函數來建立，因為Conv2D相較Conv1D、Conv3D更適合用於圖像處理領域，卷積層會輸出指定kernal數的特徵圖，並藉由MaxPooling2D池化層函數對輸入的所有特徵圖做裁減，保留重要的特徵，而使用MaxPooling2D不使用MaxPooling1D、MaxPooling3D的原因跟卷積層同理，因為MaxPooling2D更適合用於二維圖像資料的處理。接著建立Dropout層，用於隨機丟棄訓練用之神經元，可以降低過擬合之可能性。全連階層用於提高模型辨識能力以及建立分類器，輸出層使用softmax參數和神經元數量為5(因為有5種花的類別)來建立，輸出層會將輸入的圖像之各類的機率轉成總合為1的label，比如模型對花的分類機率為\[0.6, 0.2, 0.1, 0.1 ,0]\(請參考程式區塊第二行所定義之花類別對應的數字)經過softmax後會輸出label值\[1, 0, 0, 0, 0]，代表輸出這張圖像的分類。模型的架構藉由增加眷積層搭配池化層的數量以及增加隱藏層的神經元數量來小幅提高辨識準確度。
## 模型訓練
#### 將訓練資料進一步拆分成訓練集及驗證集，用以交叉驗證，而訓練參數是採用分類問題中最常用的參數，比如損失函數使用交叉熵，梯度下降法用最常用的adam，模型評估方式用準確度來評估。
## 模型儲存
#### 將訓練好的模型儲存到本機，可透過上傳至kaggle的輸入資料區以供下次直接載入並使用模型。
## 訓練過程
#### 根據想了解的方向，分成損失程度以及準確度，透過Sequential().fit()回傳之物件，並使用該物件之history函數搭配欲參考之參數來查看訓練過程。
## 模型載入
#### 從kaggle之資料輸入區將已上傳之模型(本專案命名模型的名稱為model，副檔名為h5)載入。
## 模型評估
#### 我認為此任務也是用recall為主要參考，因為此任務應是需要正確的分類花的種類，那透過recall指標可以清楚了解分類的正確程度。
###### precison為76/76+11+2+6+8= 76/103
###### recall為76/76+10+17+3+11= 76/117
###### F1-score為2/(103/76+117/76)= 13/14
###### accuracy為39+39+39+55/39+39+39+55+3+0+0+3+0+0= 38/55
![image](https://user-images.githubusercontent.com/68068287/157458702-b72bc75e-a41d-4c1a-9f22-997ecaf59437.png)

## 結語
#### 本專案使用CNN建立之花品種分類的圖像分類模型，透過混淆矩陣發現FP、FN的數值偏高，代表辨識能力存在一些瑕疵，我認為可能的解決方法是透過增加卷積層、池化層和隱藏層的數量，或是對訓練集做角度旋轉、偏移。因為增加卷積層和池化層的數量意味著產生更多更重要的特徵圖，適當的隱藏層數量增加讓前面的隱藏層先提取大範圍的較低階特徵，後面的隱藏層再將前面的低階特徵提取出較高階特徵，可以提高模型識別能力，而對訓練集做圖像處理比如角度旋轉都是資料擴充的行為，產生更多資料去訓練神經元，提高模型泛化能力進而降低過擬合機率。
