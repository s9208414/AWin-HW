{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np #提供ndarray操作之函式\nimport os #路徑操作的函式庫\nimport sklearn #機器學習演算法函式庫\n\npath = '../input/flowers-recognition/flowers'\n\nfor flower_type in os.listdir(path): #查看要分類的目標有幾類\n    print(flower_type)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-10T16:17:48.986924Z","iopub.execute_input":"2022-03-10T16:17:48.987296Z","iopub.status.idle":"2022-03-10T16:17:50.079873Z","shell.execute_reply.started":"2022-03-10T16:17:48.987191Z","shell.execute_reply":"2022-03-10T16:17:50.079086Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"classes = {'dandelion':0,'daisy':1,'sunflower':2,'tulip':3,'rose':4} #定義目標類別對應的編號","metadata":{"execution":{"iopub.status.busy":"2022-03-10T16:17:51.540321Z","iopub.execute_input":"2022-03-10T16:17:51.540662Z","iopub.status.idle":"2022-03-10T16:17:51.546874Z","shell.execute_reply.started":"2022-03-10T16:17:51.540630Z","shell.execute_reply":"2022-03-10T16:17:51.546031Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import cv2 #圖片讀入所需函式庫\nimport random #用他提供的函式來打散資料集\n\nRESIZE_SIZE = 150 #統一輸入圖片大小\nallImg = [] #希望存放所有改變尺寸後的圖片與對應的類別編號組成list的list\nX = [] #放置其他特徵\nY = [] #放置目標特徵\n\ndef readImg(path): #從路徑讀入資料集\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            filename = os.path.join(dirname, filename)\n            image = cv2.imread(filename ,cv2.IMREAD_COLOR) #以原始色彩讀入圖片\n            resized_image = cv2.resize(image ,(RESIZE_SIZE,RESIZE_SIZE)) #縮放圖片尺寸\n            #allImg.append([resized_image,classes.index(os.path.basename(dirname))])\n            allImg.append([resized_image,classes[os.path.basename(dirname)]]) #在allImg加入每一張圖片及對應的類別組成的list\n            #print(os.path.basename(dirname))\n            #print(os.path.join(dirname, filename))\n    random.shuffle(allImg) #打散串列元素\n    for Img,f_type in allImg:\n        X.append(Img)\n        Y.append(f_type)\n    return np.array(X),np.array(Y) #轉成ndarray以方便後續串列操作\n            \nX,Y = readImg(path) #讀入圖片並分離訓練特徵與目標特徵\n\nprint(X.dtype)\nprint(Y.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T16:17:53.112190Z","iopub.execute_input":"2022-03-10T16:17:53.112649Z","iopub.status.idle":"2022-03-10T16:18:47.223302Z","shell.execute_reply.started":"2022-03-10T16:17:53.112610Z","shell.execute_reply":"2022-03-10T16:18:47.222284Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split #用以將原始所提供資料集分為訓練集和測試集\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.1) #分割資料集為90%的訓練集及10%的測試集\n#確認圖片形狀是否有成功重塑成150*150*3\nprint('X_train.shape={},Y_train.shape={}'.format(X_train.shape, Y_train.shape))\nprint('X_test.shape={},Y_test.shape={}'.format(X_test.shape, Y_test.shape))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T16:19:07.207159Z","iopub.execute_input":"2022-03-10T16:19:07.207525Z","iopub.status.idle":"2022-03-10T16:19:07.517915Z","shell.execute_reply.started":"2022-03-10T16:19:07.207487Z","shell.execute_reply":"2022-03-10T16:19:07.516620Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#因為每一張圖片的所有像素值都是0~255，對每一像素除以255讓所有像素的值落在0~1之間\nX_train = X_train / 255\nX_test = X_test / 255","metadata":{"execution":{"iopub.status.busy":"2022-03-10T16:19:08.730038Z","iopub.execute_input":"2022-03-10T16:19:08.731121Z","iopub.status.idle":"2022-03-10T16:19:09.999744Z","shell.execute_reply.started":"2022-03-10T16:19:08.731079Z","shell.execute_reply":"2022-03-10T16:19:09.998946Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils #對目標特徵做one-hot-encoding，讓類別轉成0跟1以方便程式計算\nY_train = np_utils.to_categorical(Y_train)\nY_test_categories = Y_test\nY_test = np_utils.to_categorical(Y_test)\n'''import tensorflow as tf\nY_train = tf.cast(Y_train,dtype = tf.int32)\nY_train = tf.squeeze(Y_train)\nY_train = tf.one_hot(Y_train,depth = 10)'''","metadata":{"execution":{"iopub.status.busy":"2022-03-10T16:19:10.921112Z","iopub.execute_input":"2022-03-10T16:19:10.922126Z","iopub.status.idle":"2022-03-10T16:19:17.536942Z","shell.execute_reply.started":"2022-03-10T16:19:10.922067Z","shell.execute_reply":"2022-03-10T16:19:17.535613Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential #建立序列物件所需函式庫\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D #建立多層網路所需的個別網路所對應的函式庫\n\n'''\nConv2D()參數 -> \nfilters:核數，類似早期對一張圖用window去做卷積的概念(不太確定) \nkernel_size:核(window)的大小 ; \npadding:window卷積到圖片邊界的處理方式 \ninput_shape:輸入的圖片大小 \nactivation:激發函數，憑藉經驗去調整 \n'''\n#建立序列物件\nmodel = Sequential() \n#建立卷積層搭配參數，輸出16個150*150*3的特徵圖\nmodel.add(Conv2D(filters=16,kernel_size=(5,5),padding='same',input_shape=(150,150,3),activation='relu'))\n#建立池化層搭配將上層輸出的特徵圖大小簡化成一半並保留重要特徵\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n#建立卷積層並接收上層輸出後，搭配參數，輸出36個75*75*3的特徵圖\nmodel.add(Conv2D(filters=36,kernel_size=(5,5),padding='same',input_shape=(75,75,3),activation='relu'))\n#建立池化層搭配將上層輸出的特徵圖大小簡化成1/3並保留重要特徵\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n#建立卷積層並接收上層輸出後，搭配參數，輸出56個25*25*3的特徵圖\nmodel.add(Conv2D(filters=56,kernel_size=(5,5),padding='same',input_shape=(25,25,3),activation='relu'))\n#建立池化層搭配將上層輸出的特徵圖大小簡化成1/3並保留重要特徵\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n#隨機丟棄25%的神經元，讓每1次batch的訓練都可能訓練到不同的神經元，用以防止過擬合\nmodel.add(Dropout(0.25))\n#將上層的輸入平坦化，把所有特徵值轉為一維資料以供後續的全連結層使用\nmodel.add(Flatten())\n#隱藏層，用以提高模型準確度\nmodel.add(Dense(256,activation='relu'))\n#隨機丟棄50%的神經元，讓每1次batch的訓練都可能訓練到不同的神經元，用以防止過擬合\nmodel.add(Dropout(0.5))\n#輸出層，使用softmax作為輸出層的激發函數，第一個參數是要分類目標的數量\nmodel.add(Dense(5,activation='softmax'))\n#查看模型架構\nmodel.summary()  \n","metadata":{"execution":{"iopub.status.busy":"2022-03-08T03:56:58.837774Z","iopub.execute_input":"2022-03-08T03:56:58.838089Z","iopub.status.idle":"2022-03-08T03:56:58.952208Z","shell.execute_reply.started":"2022-03-08T03:56:58.838047Z","shell.execute_reply":"2022-03-08T03:56:58.951308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#定義訓練時的參數，損失函數用分類模型最常用的交叉熵，梯度下降法用最常用的adam，模型評估方式用準確度來評估\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n#訓練模型，將訓練集拆分80%為訓練集以及20%為訓練時的驗證集，將所有訓練集訓練10次(epochs=10)後終止訓練，每一批次(batch)訓練都是將300張圖片輸入，大概一個epoch會有3108/300個batch(3108是訓練集數量)\ntrain_history = model.fit(x=X_train,y=Y_train,validation_data=(X_test, Y_test),validation_split=0.2,epochs=10,batch_size=300,verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T03:56:58.954047Z","iopub.execute_input":"2022-03-08T03:56:58.954297Z","iopub.status.idle":"2022-03-08T04:01:47.267559Z","shell.execute_reply.started":"2022-03-08T03:56:58.954266Z","shell.execute_reply":"2022-03-08T04:01:47.266264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./model.h5') #儲存模型到本機","metadata":{"execution":{"iopub.status.busy":"2022-03-08T04:01:47.269227Z","iopub.execute_input":"2022-03-08T04:01:47.269507Z","iopub.status.idle":"2022-03-08T04:01:47.325652Z","shell.execute_reply.started":"2022-03-08T04:01:47.269477Z","shell.execute_reply":"2022-03-08T04:01:47.324816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n#繪製訓練時的訓練集的準確度(或損失)和驗證集的準確度(或損失)\ndef show_train_history(train_history,standard,train,validation):\n    plt.plot(train_history.history[train])\n    plt.plot(train_history.history[validation])\n    plt.title(standard)\n    plt.ylabel('train')\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'validation'], loc='center right')\n    plt.show()\n    \nshow_train_history(train_history,'accuracy','accuracy','val_accuracy')\nshow_train_history(train_history,'loss','loss','val_loss')","metadata":{"execution":{"iopub.status.busy":"2022-03-08T04:01:47.326843Z","iopub.execute_input":"2022-03-08T04:01:47.327135Z","iopub.status.idle":"2022-03-08T04:01:47.758748Z","shell.execute_reply.started":"2022-03-08T04:01:47.327104Z","shell.execute_reply":"2022-03-08T04:01:47.758042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('../input/keras-cnn-model/model.h5') #先從本機上傳模型到input資料夾後，再載入訓練好的模型","metadata":{"execution":{"iopub.status.busy":"2022-03-10T16:19:25.613257Z","iopub.execute_input":"2022-03-10T16:19:25.613629Z","iopub.status.idle":"2022-03-10T16:19:26.058646Z","shell.execute_reply.started":"2022-03-10T16:19:25.613567Z","shell.execute_reply":"2022-03-10T16:19:26.057854Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(X_test, Y_test)\nscores[1] #只顯示模型的準確度(根據模型訓練的參數定義，可選其他指標值，比如recall)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T16:19:27.194828Z","iopub.execute_input":"2022-03-10T16:19:27.195333Z","iopub.status.idle":"2022-03-10T16:19:29.178623Z","shell.execute_reply.started":"2022-03-10T16:19:27.195282Z","shell.execute_reply":"2022-03-10T16:19:29.177458Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(X_test) #對測試集預測\n\nfrom sklearn.metrics import classification_report,confusion_matrix\n#用以繪製confusion matrix之函式庫\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n#一開始沒有下面的程式碼會報錯，查網路說因為預測向量與目標特徵向量內的元素不對稱，所以也要把預測向量做one-hot-encoding\nfor i in range(len(prediction)):\n    max_value = max(prediction[i])\n    for j in range(len(prediction[i])):\n        if max_value == prediction[i][j]:\n            prediction[i][j] = 1\n        else:\n            prediction[i][j] = 0\nprint(Y_test)\nprint(prediction)\nprint('分類報告:\\n',classification_report(Y_test,prediction))\n#使用參數average='macro'，期望輸出不受各類別樣本數影響\nprecision_score,recall_score,f1_score,support_score= sklearn.metrics.precision_recall_fscore_support(Y_test,prediction,average='macro')\naccuracy = sklearn.metrics.accuracy_score(Y_test,prediction)\nprint('accuracy_score:',accuracy)\nprint('precision_score:',precision_score)\nprint('recall_score:',recall_score)\nprint('f1_score:',f1_score)\nprint('support_score:',support_score)\nprint('混淆矩陣:')\n#因為confusion matrix不接受傳入one-hot-encoding的資料，所以要將測試資料以及預測向量做reverse-one-hot-encoding轉成10進位\nplt.figure(figsize=(5,5))\nsns.heatmap(confusion_matrix(Y_test.argmax(axis=1), prediction.argmax(axis=1)),annot=True,cmap=plt.cm.Blues)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T16:19:40.693304Z","iopub.execute_input":"2022-03-10T16:19:40.693684Z","iopub.status.idle":"2022-03-10T16:19:42.714246Z","shell.execute_reply.started":"2022-03-10T16:19:40.693643Z","shell.execute_reply":"2022-03-10T16:19:42.712998Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(20,20)) #設定整個繪製區域大小\nrand = np.random.randint(0,len(X_test),10) #隨機從測試集取10個樣本來測試\naxis = 1 #繪製子區域的座標起始值\n#print(len(X_test))\n#print(rand)\nfor i in rand:\n    plt.subplot(5,2,axis) #row:5 col:2\n    plt.imshow(X_test[i]) #顯示圖片\n    plt.title(\"True : {} , Predict : {}\".format(np.argmax(Y_test[i]) ,np.argmax(prediction[i]))) #對類別作one-hot-reverse-encoding轉成一開始所設定的類別編號\n    axis+=1","metadata":{"execution":{"iopub.status.busy":"2022-03-10T16:19:47.034834Z","iopub.execute_input":"2022-03-10T16:19:47.035154Z","iopub.status.idle":"2022-03-10T16:19:49.169905Z","shell.execute_reply.started":"2022-03-10T16:19:47.035123Z","shell.execute_reply":"2022-03-10T16:19:49.168802Z"},"trusted":true},"execution_count":11,"outputs":[]}]}